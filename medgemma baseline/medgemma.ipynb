{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd45d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm # ç”¨æ–¼é¡¯ç¤ºé€²åº¦æ¢\n",
    "import csv\n",
    "\n",
    "# --- 1. å¸¸æ•¸èˆ‡æç¤ºè©å®šç¾© (ä¾†è‡ªæ‚¨çš„ GRPO è…³æœ¬) ---\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€åå°ˆé–€æ ¹æ“šæ‚£è€…ç”¨è—¥èˆ‡ç—…å²ç´€éŒ„é æ¸¬ ICD-10 ç·¨ç¢¼çš„é†«å­¸å°ˆå®¶ã€‚  \n",
    "è«‹åš´æ ¼éµå®ˆä»¥ä¸‹ä½œç­”æ ¼å¼ï¼š  \n",
    "\n",
    "<reasoning>  \n",
    "é€æ­¥æ¨ç†ï¼šé€æ¢èªªæ˜ç—…ä¾‹ä¸­æ¯å€‹è‡¨åºŠè³‡è¨Šï¼ˆç—‡ç‹€ã€è¨ºæ–·ã€æª¢æŸ¥çµæœã€æ—¢å¾€ç—…å²ã€ç”¨è—¥ç­‰ï¼‰å¯èƒ½å°æ‡‰çš„ ICD-10 ç·¨ç¢¼ï¼Œä¸¦åœ¨æœ€å¾Œç¸½çµå‡ºæœ€åˆç†çš„ç·¨ç¢¼é›†åˆã€‚  \n",
    "</reasoning>  \n",
    "<answer>  \n",
    "åƒ…è¼¸å‡ºæœ€çµ‚çš„ ICD-10 ç·¨ç¢¼ï¼Œä½¿ç”¨è‹±æ–‡é€—è™Ÿåˆ†éš”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–æ–‡å­—æˆ–è§£é‡‹ã€‚  \n",
    "</answer>  \n",
    "\"\"\"\n",
    "\n",
    "EXAMPLE_QUESTION = \"\"\"\n",
    "Sex: F\n",
    "Service: MEDICINE\n",
    "Allergies: Aspirin\n",
    "Attending: ___\n",
    "Chief Complaint: weakness, diarrhea\n",
    "Major Surgical or Invasive Procedure: None\n",
    "\n",
    "History of Present Illness:\n",
    "Ms. ___ is a ___ year-old woman with PMH significant for chronic anemia, osteoporosis, hypertension, ataxia, and recent L5 fracture in the setting of recurrent falls who presents from home with fatigue and generalized weakness and diarrhea.  \n",
    "\n",
    "The patient's recent history is notable for the follow:  \n",
    "- On ___, she presented with 4 days of LBP s/p fall from standing at which time imaging revealed acute L5 fracture. She was evaluated by Spine team who recommended early mobilization, pain control, but no brace required. She was evaluated by ___, and discharged to ___.  \n",
    "- She was discharged home with ___ on ___.  \n",
    "- On ___, she again presented to ___ s/p fall from standing while trying to reach for a glass of water. She did have a occipital scalp hematoma, but imaging including ___, C-spine CT, and L hip X-ray were negative for acute process so patient was discharged home.  \n",
    "\n",
    "She now represents with generalized fatigue and diarrhea. In the setting of opiates for her L5 fracture, the patient has had constipation (5 days with no BM) for which she took a \"natural laxative\" the evening prior to presentation. The patient had 2 bowel movements in the morning of presentation and one episode of incontinence with diarrhea while sleeping. In this setting, she felt very weak and called EMS and was brought to ___ ED.\n",
    "\n",
    "What ICD-10 codes should be assigned? Please just tell me which codes in the end\n",
    "\"\"\"\n",
    "EXAMPLE_REASONING = \"\"\"The patient has chronic anemia, documented and clinically relevant, which corresponds to D500.  \n",
    "There is vitamin deficiency suggested, which fits E538.  \n",
    "She also has visual impairment history, which maps to H548.  \n",
    "Hypertension is a chronic condition, coded as I10.  \n",
    "Diarrhea due to laxative use is coded as K521 (toxic gastroenteritis and colitis).  \n",
    "Her recent fracture with underlying osteoporosis corresponds to M810.  \n",
    "Ataxia is a chronic neurologic condition, coded as R270.  \n",
    "There is adverse effect of drugs (laxatives/opioids), so T474X5A applies.  \n",
    "Environmental factor of injury is Y92099 (unspecified place of occurrence).  \n",
    "She also has aspirin allergy, captured by Z9181.  \n",
    "\n",
    "Therefore, the most appropriate ICD-10 codes are:\n",
    "</reasoning>\n",
    "\"\"\"\n",
    "\n",
    "EXAMPLE_ANSWER = \"D500 E538 H548 I10 K521 M810 R270 T474X5A Y92099 Z9181\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3586d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_icd_answer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    å¾æ¨¡å‹çš„å®Œæ•´å›è¦†æˆ–æ¨™æº–ç­”æ¡ˆä¸­æå– ICD-10 ç·¨ç¢¼ã€‚\n",
    "    æ”¯æ´ï¼š\n",
    "    - <answer>...</answer> æ¨™ç±¤æ ¼å¼\n",
    "    - \"ICD10 ç·¨ç¢¼ï¼š\" é–‹é ­çš„æ ¼å¼\n",
    "    - ç´”ç·¨ç¢¼åˆ—è¡¨\n",
    "    \n",
    "    Returns:\n",
    "        ç©ºæ ¼åˆ†éš”çš„ ICD ç·¨ç¢¼å­—ä¸²,ä¾‹å¦‚: \"A01.0 B02.1\"\n",
    "    \"\"\"\n",
    "    # 1. å„ªå…ˆå°‹æ‰¾ <answer> æ¨™ç±¤\n",
    "    text = text.replace('.', '')\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        codes_str = match.group(1).strip()\n",
    "    else:\n",
    "        # 2. å°‹æ‰¾ \"ICD10 ç·¨ç¢¼ï¼š\" æˆ–é¡ä¼¼æ ¼å¼\n",
    "        match = re.search(r\"ICD[\\s-]?10\\s*ç·¨ç¢¼[ï¼š:]\\s*(.*?)(?:[ã€‚\\n]|$)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            codes_str = match.group(1).strip()\n",
    "        else:\n",
    "            # 3. å°‡æ•´å€‹æ–‡å­—è¦–ç‚ºç·¨ç¢¼\n",
    "            codes_str = text.strip()\n",
    "    \n",
    "    # ç§»é™¤å¸¸è¦‹çš„éç·¨ç¢¼æ–‡å­—\n",
    "    codes_str = re.sub(r'####|ICD[\\s-]?10|ç·¨ç¢¼[ï¼š:]?', '', codes_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # åˆ†å‰²ç·¨ç¢¼ï¼ˆç”¨é€—è™Ÿã€ç©ºæ ¼ã€æ›è¡Œåˆ†éš”ï¼‰\n",
    "    codes_list = re.split(r'[,ï¼Œ\\s\\n]+', codes_str)\n",
    "    \n",
    "    # éæ¿¾ä¸¦æ¸…ç†ç·¨ç¢¼\n",
    "    cleaned_codes = []\n",
    "    for code in codes_list:\n",
    "        code = code.strip('ã€‚ã€,ï¼Œ:ï¼š.;ï¼›')  \n",
    "        # åªä¿ç•™çœ‹èµ·ä¾†åƒ ICD-10 ç·¨ç¢¼çš„å­—ä¸²ï¼ˆå­—æ¯é–‹é ­+æ•¸å­—ï¼‰\n",
    "        if code and re.match(r'^[A-Z][0-9]', code, re.IGNORECASE):\n",
    "            cleaned_codes.append(code.upper())  # âœ… çµ±ä¸€å¤§å¯«\n",
    "    \n",
    "    # æ’åºã€å»é‡\n",
    "    cleaned_codes = sorted(list(set(cleaned_codes)))\n",
    "    return \" \".join(cleaned_codes)\n",
    "\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    \"\"\"æå– <answer> æ¨™ç±¤å…§çš„å…§å®¹\"\"\"\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    answer = answer.strip()\n",
    "    return answer\n",
    "\n",
    "\n",
    "def is_text(text: str) -> bool:\n",
    "    \"\"\"åˆ¤æ–·è¼¸å…¥å­—ä¸²æ˜¯å¦ä¸»è¦ç‚ºæ–‡å­—æ•˜è¿°ï¼ˆè€Œé ICD code ç­‰çŸ­ç·¨ç¢¼ï¼‰\"\"\"\n",
    "    letters_and_spaces = sum(c.isalpha() or c.isspace() for c in text)\n",
    "    ratio = letters_and_spaces / max(1, len(text))  \n",
    "    return ratio > 0.5\n",
    "\n",
    "\n",
    "def compute_f1(pred: str, true: str) -> float:\n",
    "    \"\"\"\n",
    "    è¨ˆç®— F1 åˆ†æ•¸ (å‰ä¸‰å€‹å­—ç¬¦åŒ¹é…å³ç®—æ­£ç¢º)\n",
    "    \n",
    "    Args:\n",
    "        pred: é æ¸¬çš„ ICD ç·¨ç¢¼å­—ä¸²,ä¾‹å¦‚ \"A010 B021\"\n",
    "        true: çœŸå¯¦çš„ ICD ç·¨ç¢¼å­—ä¸²,ä¾‹å¦‚ \"A010 C032\"\n",
    "    \n",
    "    Returns:\n",
    "        F1 åˆ†æ•¸ (0.0 åˆ° 1.0)\n",
    "    \"\"\"\n",
    "    # å°‡å­—ä¸²è½‰æ›ç‚º set\n",
    "    pred = pred.replace('.', '')\n",
    "    true = true.replace('.', '')\n",
    "    \n",
    "    def parse_codes(text):\n",
    "        if ',' in text:\n",
    "            return set(code.strip().upper() for code in text.split(',') if code.strip())\n",
    "        else:\n",
    "            return set(code.strip().upper() for code in text.split() if code.strip())\n",
    "    \n",
    "    pred_set = parse_codes(pred)\n",
    "    true_set = parse_codes(true)\n",
    "    \n",
    "    # å¦‚æœéƒ½æ˜¯ç©ºé›†åˆ,è¦–ç‚ºå®Œå…¨åŒ¹é…\n",
    "    if not pred_set and not true_set:\n",
    "        return 1.0\n",
    "    \n",
    "    # è½‰æ›ç‚ºå‰ä¸‰å€‹å­—ç¬¦çš„é›†åˆ\n",
    "    def get_prefix_set(codes):\n",
    "        return set(code[:3] for code in codes if len(code) >= 3)\n",
    "    \n",
    "    pred_prefix = get_prefix_set(pred_set)\n",
    "    true_prefix = get_prefix_set(true_set)\n",
    "    \n",
    "    # è¨ˆç®— TP, FP, FN\n",
    "    tp = len(pred_prefix & true_prefix)\n",
    "    fp = len(pred_prefix - true_prefix)\n",
    "    fn = len(true_prefix - pred_prefix)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f\"âœ… Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "# def strict_format_check(prediction: str, ground_truth: str) -> bool:\n",
    "#     \"\"\"\n",
    "#     åš´æ ¼æ ¼å¼æª¢æŸ¥\n",
    "    \n",
    "#     Args:\n",
    "#         prediction: é æ¸¬çš„ ICD ç·¨ç¢¼å­—ä¸²\n",
    "#         ground_truth: çœŸå¯¦çš„ ICD ç·¨ç¢¼å­—ä¸²\n",
    "    \n",
    "#     Returns:\n",
    "#         True å¦‚æœæ ¼å¼æ­£ç¢º,False å¦å‰‡\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # å…ˆç§»é™¤æ‰€æœ‰å¥é»\n",
    "#         prediction = prediction.replace('.', '')\n",
    "        \n",
    "#         def parse_codes(text):\n",
    "#             if ',' in text:\n",
    "#                 return set(code.strip() for code in text.split(',') if code.strip())\n",
    "#             else:\n",
    "#                 return set(code.strip() for code in text.split() if code.strip())\n",
    "        \n",
    "#         pred_set = parse_codes(prediction)\n",
    "        \n",
    "#         # æª¢æŸ¥æ˜¯å¦æœ‰è§£æåˆ°ä»»ä½•ç·¨ç¢¼\n",
    "#         if not pred_set:\n",
    "#             return False\n",
    "        \n",
    "#         # ICD-10 æ ¼å¼: å­—æ¯é–‹é ­,å¾Œæ¥ 2-6 å€‹å­—æ¯æˆ–æ•¸å­—\n",
    "#         icd_pattern = re.compile(r'^[A-Z][0-9A-Z]{2,6}$')\n",
    "        \n",
    "#         # é©—è­‰æ¯å€‹ç·¨ç¢¼æ˜¯å¦ç¬¦åˆæ ¼å¼\n",
    "#         for code in pred_set:\n",
    "#             if not icd_pattern.match(code):\n",
    "#                 return False\n",
    "        \n",
    "#         return True\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ æ ¼å¼æª¢æŸ¥éŒ¯èª¤: {e}\")\n",
    "#         return False\n",
    "\n",
    "\n",
    "def count_xml(text: str) -> float:\n",
    "    \"\"\"\n",
    "    æª¢æŸ¥ XML æ¨™ç±¤æ ¼å¼çš„å®Œæ•´æ€§\n",
    "    \n",
    "    Returns:\n",
    "        åˆ†æ•¸ (0.0 åˆ° 0.5),åˆ†æ•¸è¶Šé«˜è¡¨ç¤ºæ ¼å¼è¶Šå®Œæ•´\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    \n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        score += 0.125\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        score += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        score += 0.125\n",
    "        # æ‡²ç½° </answer> å¾Œæœ‰å¤šé¤˜å…§å®¹\n",
    "        extra_content = len(text.split(\"\\n</answer>\\n\")[-1])\n",
    "        score -= extra_content * 0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        score += 0.125\n",
    "        # æ‡²ç½° </answer> å¾Œæœ‰å¤šé¤˜å…§å®¹\n",
    "        extra_content = len(text.split(\"\\n</answer>\")[-1]) - 1\n",
    "        score -= max(0, extra_content) * 0.001\n",
    "    \n",
    "    return max(0.0, score)  # âœ… ç¢ºä¿ä¸æœƒæ˜¯è² æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14ac5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¼‰å…¥æ¨¡å‹: ./models/medgemma-4b-it ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹è¼‰å…¥å®Œç•¢ã€‚\n",
      "æ­£åœ¨è¼‰å…¥ note_icd_data.jsonl ...\n",
      "è³‡æ–™è¼‰å…¥å®Œç•¢ï¼Œå…± 3852 ç­†ã€‚\n"
     ]
    }
   ],
   "source": [
    "# --- 3. è¼‰å…¥æ¨¡å‹èˆ‡ Tokenizer ---\n",
    "model_path = \"./models/medgemma-4b-it\" \n",
    "\n",
    "print(f\"æ­£åœ¨è¼‰å…¥æ¨¡å‹: {model_path} ...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"æ¨¡å‹è¼‰å…¥å®Œç•¢ã€‚\")\n",
    "\n",
    "# --- 4. è¼‰å…¥ä¸¦è™•ç†è³‡æ–™ ---\n",
    "\n",
    "print(\"æ­£åœ¨è¼‰å…¥ note_icd_data.jsonl ...\")\n",
    "chat_style_data = []\n",
    "try:\n",
    "    with open(\"note_icd_data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 4000:\n",
    "                print(f\"å·²è®€å–å‰ {i} ç­†è³‡æ–™ (ä¸Šé™ 10 ç­†)ã€‚\")\n",
    "                break\n",
    "            \n",
    "            item = json.loads(line)  \n",
    "            \n",
    "            chat_prompt = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": EXAMPLE_QUESTION},\n",
    "                {\"role\": \"assistant\", \"content\": f\"<reasoning>{EXAMPLE_REASONING}</reasoning><answer>{EXAMPLE_ANSWER}</answer>\"},\n",
    "                {\"role\": \"user\", \"content\": item[\"question\"]}\n",
    "            ]\n",
    "            \n",
    "            ground_truth_answer= extract_icd_answer(item[\"answer\"])\n",
    "            \n",
    "            chat_style_data.append({\n",
    "                \"prompt\": chat_prompt,\n",
    "                \"answer\": ground_truth_answer,\n",
    "                \"raw_question\": item[\"question\"]\n",
    "            })\n",
    "except FileNotFoundError:\n",
    "    print(\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° 'note_icd_data.jsonl' æª”æ¡ˆã€‚\")\n",
    "    exit()\n",
    "\n",
    "print(f\"è³‡æ–™è¼‰å…¥å®Œç•¢ï¼Œå…± {len(chat_style_data)} ç­†ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b64d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ CSV æª”æ¡ˆå·²åˆå§‹åŒ–: med_baseline.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Baseline] åŸ·è¡Œæ¨è«–èˆ‡è©•ä¼°:   0%|          | 1/3852 [00:11<12:27:26, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“ æ¨£æœ¬ #1\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– æ¨¡å‹å®Œæ•´å›ç­”:\n",
      "--------------------------------------------------------------------------------\n",
      "<reasoning>\n",
      "The patient has chronic anemia, documented and clinically relevant, which corresponds to D500.\n",
      "There is vitamin deficiency suggested, which fits E538.\n",
      "She also has visual impairment history, which maps to H548.\n",
      "Hypertension is a chronic condition, coded as I10.\n",
      "Diarrhea due to laxative use is coded as K521 (toxic gastroenteritis and colitis).\n",
      "Her recent fracture with underlying osteoporosis corresponds to M810.\n",
      "Ataxia is a chronic neurologic condition, coded as R270.\n",
      "There is adverse effect of drugs (laxatives/opioids), so T474X5A applies.\n",
      "Environmental factor of injury is Y92099 (unspecified place of occurrence).\n",
      "She also has aspirin allergy, captured by Z9181.\n",
      "\n",
      "Therefore, the most appropriate ICD-10 codes are:\n",
      "</reasoning>\n",
      "<answer>D500 E538 H548 I10 K521 M810 R270 T474X5A Y92099 Z9181</answer>\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ“Š å®Œæˆçš„å›è¦†é•·åº¦ (token æ•¸): 250\n",
      "ğŸ” æå–çš„ ICD-10 ç·¨ç¢¼: D500 E538 H548 I10 K521 M810 R270 T474X5A Y92099 Z9181\n",
      "\n",
      "ğŸ¯ Ground Truth Answer:\n",
      "   D500 E538 H548 I10 K521 M810 R270 T474X5A Y92099 Z9181\n",
      "âœ… Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
      "âœ… Baseline F1 åˆ†æ•¸: 1.0000\n",
      "ğŸ’¾ çµæœå·²å„²å­˜è‡³ med_baseline.csv (ç¬¬ 1 ç­†)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. åŸ·è¡Œ Baseline æ¨è«–ä¸¦è¨ˆç®—æ‰€æœ‰æŒ‡æ¨™ ---\n",
    "# ç”¨æ–¼ Baseline Micro-F1\n",
    "all_predictions_baseline = []\n",
    "all_ground_truths_baseline = []\n",
    "all_acc_baseline = []\n",
    "all_strict_baseline = []\n",
    "all_completion_lengths = []\n",
    "\n",
    "# === æ–°å¢ï¼šåˆå§‹åŒ– CSV æª”æ¡ˆ,å¯«å…¥è¡¨é ­ ===\n",
    "csv_filename = \"med_baseline.csv\"\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['accuracy_reward', 'completion_length', 'ground_truths_ans', 'predictions_ans']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "print(f\"ğŸ“ CSV æª”æ¡ˆå·²åˆå§‹åŒ–: {csv_filename}\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, item in enumerate(tqdm(chat_style_data, desc=\"[Baseline] åŸ·è¡Œæ¨è«–èˆ‡è©•ä¼°\"), 1):\n",
    "        chat_prompt = item[\"prompt\"]\n",
    "        gt_answer = item[\"answer\"]\n",
    "        \n",
    "        try:\n",
    "            prompt_str = tokenizer.apply_chat_template(\n",
    "                chat_prompt, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # æ‰‹å‹•å›é€€æ ¼å¼ (é©ç”¨æ–¼ MedGemma)\n",
    "            print(f\"æ‰‹å‹•å›é€€æ ¼å¼: {e}\")\n",
    "            prompt_str = (\n",
    "                f\"<start_of_turn>system\\n{chat_prompt[0]['content']}<end_of_turn>\\n\"\n",
    "                f\"<start_of_turn>user\\n{chat_prompt[1]['content']}<end_of_turn>\\n\"\n",
    "                f\"<start_of_turn>model\\n{chat_prompt[2]['content']}<end_of_turn>\\n\"\n",
    "                f\"<start_of_turn>user\\n{chat_prompt[3]['content']}<end_of_turn>\\n\"\n",
    "                f\"<start_of_turn>model\\n\"\n",
    "            )\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            prompt_str, \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=4096,\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2000,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        input_length = inputs.input_ids.shape[1]\n",
    "        generated_tokens = outputs[0][input_length:]\n",
    "        assistant_reply = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        # === å°å‡ºå®Œæ•´è³‡è¨Š ===\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ“ æ¨£æœ¬ #{idx}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nğŸ¤– æ¨¡å‹å®Œæ•´å›ç­”:\")\n",
    "        print(\"-\"*80)\n",
    "        print(assistant_reply)\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        all_ground_truths_baseline.append(gt_answer)\n",
    "        \n",
    "        # è¨˜éŒ„ completion length (token æ•¸)\n",
    "        completion_length = len(generated_tokens)\n",
    "        print(f\"\\nğŸ“Š å®Œæˆçš„å›è¦†é•·åº¦ (token æ•¸): {completion_length}\")\n",
    "        all_completion_lengths.append(completion_length)\n",
    "        \n",
    "        # è¨ˆç®— Baseline metrics\n",
    "        predicted_codes_baseline = extract_icd_answer(assistant_reply)\n",
    "        print(f\"ğŸ” æå–çš„ ICD-10 ç·¨ç¢¼: {predicted_codes_baseline}\")\n",
    "        all_predictions_baseline.append(predicted_codes_baseline)\n",
    "\n",
    "        print(f\"\\nğŸ¯ Ground Truth Answer:\")\n",
    "        print(f\"   {gt_answer}\")\n",
    "        \n",
    "        acc_baseline = compute_f1(predicted_codes_baseline, gt_answer)\n",
    "        print(f\"âœ… Baseline F1 åˆ†æ•¸: {acc_baseline:.4f}\")\n",
    "        all_acc_baseline.append(acc_baseline)\n",
    "        \n",
    "        # strict_baseline = strict_format_check(predicted_codes_baseline, gt_answer)\n",
    "        # print(f\"ğŸ“‹ åš´æ ¼æ ¼å¼æª¢æŸ¥çµæœ: {'âœ“ é€šé' if strict_baseline else 'âœ— æœªé€šé'}\")\n",
    "        # all_strict_baseline.append(strict_baseline)\n",
    "        \n",
    "        \n",
    "        with open(csv_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writerow({\n",
    "                'accuracy_reward': acc_baseline,\n",
    "                'completion_length': completion_length,\n",
    "                'ground_truths_ans': gt_answer,\n",
    "                'predictions_ans': predicted_codes_baseline\n",
    "            })\n",
    "        \n",
    "        print(f\"ğŸ’¾ çµæœå·²å„²å­˜è‡³ {csv_filename} (ç¬¬ {idx} ç­†)\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ æ¨è«–å®Œæˆ!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- 6. é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ ---\n",
    "if not all_predictions_baseline:\n",
    "    print(\"æ²’æœ‰å¯è©•ä¼°çš„çµæœã€‚\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"  Baseline (medgemma-4b-it) æœ€çµ‚çµ±è¨ˆ\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"âœ… ç¸½å…±è™•ç†: {len(all_acc_baseline)} ç­†è³‡æ–™\")\n",
    "    print(f\"ğŸ“Š å¹³å‡ F1 åˆ†æ•¸: {sum(all_acc_baseline)/len(all_acc_baseline):.4f}\")\n",
    "    print(f\"ğŸ“ å¹³å‡å›è¦†é•·åº¦: {sum(all_completion_lengths)/len(all_completion_lengths):.1f} tokens\")\n",
    "    print(f\"ğŸ’¾ çµæœå·²å®Œæ•´å„²å­˜è‡³: {csv_filename}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
