{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22425d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ ------------\n",
      "accelerate               1.12.0\n",
      "aiohappyeyeballs         2.6.1\n",
      "aiohttp                  3.13.2\n",
      "aiosignal                1.4.0\n",
      "anyio                    4.12.0\n",
      "asttokens                3.0.1\n",
      "attrs                    25.4.0\n",
      "bitsandbytes             0.48.2\n",
      "certifi                  2025.11.12\n",
      "charset-normalizer       3.4.4\n",
      "comm                     0.2.3\n",
      "cut-cross-entropy        25.1.1\n",
      "datasets                 4.3.0\n",
      "debugpy                  1.8.17\n",
      "decorator                5.2.1\n",
      "dill                     0.4.0\n",
      "docstring_parser         0.17.0\n",
      "executing                2.2.1\n",
      "filelock                 3.20.0\n",
      "frozenlist               1.8.0\n",
      "fsspec                   2025.9.0\n",
      "h11                      0.16.0\n",
      "hf_transfer              0.1.9\n",
      "hf-xet                   1.2.0\n",
      "httpcore                 1.0.9\n",
      "httpx                    0.28.1\n",
      "huggingface-hub          0.36.0\n",
      "idna                     3.11\n",
      "ipykernel                7.1.0\n",
      "ipython                  9.8.0\n",
      "ipython_pygments_lexers  1.1.1\n",
      "jedi                     0.19.2\n",
      "Jinja2                   3.1.6\n",
      "jupyter_client           8.7.0\n",
      "jupyter_core             5.9.1\n",
      "markdown-it-py           4.0.0\n",
      "MarkupSafe               3.0.3\n",
      "matplotlib-inline        0.2.1\n",
      "mdurl                    0.1.2\n",
      "mpmath                   1.3.0\n",
      "msgspec                  0.20.0\n",
      "multidict                6.7.0\n",
      "multiprocess             0.70.16\n",
      "nest-asyncio             1.6.0\n",
      "networkx                 3.6.1\n",
      "numpy                    2.3.5\n",
      "nvidia-cublas-cu12       12.8.4.1\n",
      "nvidia-cuda-cupti-cu12   12.8.90\n",
      "nvidia-cuda-nvrtc-cu12   12.8.93\n",
      "nvidia-cuda-runtime-cu12 12.8.90\n",
      "nvidia-cudnn-cu12        9.10.2.21\n",
      "nvidia-cufft-cu12        11.3.3.83\n",
      "nvidia-cufile-cu12       1.13.1.3\n",
      "nvidia-curand-cu12       10.3.9.90\n",
      "nvidia-cusolver-cu12     11.7.3.90\n",
      "nvidia-cusparse-cu12     12.5.8.93\n",
      "nvidia-cusparselt-cu12   0.7.1\n",
      "nvidia-nccl-cu12         2.27.5\n",
      "nvidia-nvjitlink-cu12    12.8.93\n",
      "nvidia-nvshmem-cu12      3.3.20\n",
      "nvidia-nvtx-cu12         12.8.90\n",
      "packaging                25.0\n",
      "pandas                   2.3.3\n",
      "parso                    0.8.5\n",
      "peft                     0.18.0\n",
      "pexpect                  4.9.0\n",
      "pillow                   12.0.0\n",
      "pip                      25.3\n",
      "platformdirs             4.5.1\n",
      "prompt_toolkit           3.0.52\n",
      "propcache                0.4.1\n",
      "protobuf                 6.33.2\n",
      "psutil                   7.1.3\n",
      "ptyprocess               0.7.0\n",
      "pure_eval                0.2.3\n",
      "pyarrow                  22.0.0\n",
      "Pygments                 2.19.2\n",
      "python-dateutil          2.9.0.post0\n",
      "pytz                     2025.2\n",
      "PyYAML                   6.0.3\n",
      "pyzmq                    27.1.0\n",
      "regex                    2025.11.3\n",
      "requests                 2.32.5\n",
      "rich                     14.2.0\n",
      "safetensors              0.7.0\n",
      "sentencepiece            0.2.1\n",
      "setuptools               65.5.0\n",
      "six                      1.17.0\n",
      "stack-data               0.6.3\n",
      "sympy                    1.14.0\n",
      "tensorboardX             2.6.4\n",
      "tokenizers               0.22.1\n",
      "torch                    2.9.1\n",
      "torchao                  0.14.1\n",
      "torchvision              0.24.1\n",
      "tornado                  6.5.2\n",
      "tqdm                     4.67.1\n",
      "traitlets                5.14.3\n",
      "transformers             4.57.3\n",
      "triton                   3.5.1\n",
      "trl                      0.24.0\n",
      "typeguard                4.4.4\n",
      "typing_extensions        4.15.0\n",
      "tyro                     1.0.0\n",
      "tzdata                   2025.2\n",
      "unsloth                  2025.12.1\n",
      "unsloth_zoo              2025.12.3\n",
      "urllib3                  2.6.1\n",
      "wcwidth                  0.2.14\n",
      "wheel                    0.45.1\n",
      "xformers                 0.0.26.post1\n",
      "xxhash                   3.6.0\n",
      "yarl                     1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d7503",
   "metadata": {},
   "source": [
    "### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452fcd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data2/icd10/venv_sft/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data2/icd10/venv_sft/lib/python3.11/site-packages/unsloth/models/rl_replacements.py:946: UserWarning: You are importing from 'trl.experimental'. APIs here are unstable and may change or be removed without notice. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
      "  import trl.experimental.openenv.utils as openenv_utils\n",
      "[unsloth_zoo.log|WARNING]Unsloth: Failed to import trl openenv: No module named 'trl.experimental.openenv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.1: Fast Qwen3 patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 2. Max memory: 47.493 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:51<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_name = \"models/Qwen3-32B\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = 2048,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f537c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.12.1 patched 64 layers with 64 QKV layers, 64 O layers and 64 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df205e1",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f66dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset1 åŸå§‹ç­†æ•¸: 1044\n",
      "Dataset2 åŸå§‹ç­†æ•¸: 213\n",
      "\n",
      "åˆä½µå¾Œç¸½ç­†æ•¸: 1257\n",
      "  - Dataset1 è²¢ç»: 1044 ç­†\n",
      "  - Dataset2 è²¢ç»: 213 ç­†\n",
      "\n",
      "æœ€çµ‚è³‡æ–™é›†ç¸½ç­†æ•¸: 1257\n",
      "\n",
      "ç¬¬ä¸€ç­†å°è©±ç¯„ä¾‹:\n",
      "[{'content': 'There is a patient with the following ICD-10 codes:ï¼šD500,E538,H548,I10,K521,M810,R270,T474X5A,Y92099,Z9181. The medical record for the Patient is as follows:Sex:   F\\n \\nService: MEDICINE\\n \\nAllergies: \\nAspirin\\n \\nAttending: ___.\\n \\nChief Complaint:\\nweakness, diarrhea\\n \\nMajor Surgical or Invasive Procedure:\\nNone\\n\\n \\nHistory of Present Illness:\\nMs. ___ is a ___ year-old woman with PMH significant for \\nchronic anemia, osteoporosis, hypertension, ataxia, and recent \\nL5 fracture in the setting of recurrent falls who presents from \\nhome with fatigue and generalized weakness and diarrhea.  \\n The patient\\'s recent history is notable for the follow:  \\n - On ___, she presented with 4 days of LBP s/p fall from \\nstanding at which time imaging revealed acute L5 fracture. She \\nwas evaluated by Spine team who recommended early mobilization, \\npain control, but no brace required. She was evaluated by ___, \\nand discharged to ___.  \\n - She was discharged home with ___ on ___.  \\n - On ___, she again presented to ___ s/p fall from \\nstanding while trying to reach for a glass of water. She did \\nhave a occipital scalp hematoma, but imaging including ___, \\nC-spine CT, and L hip X-ray were negative for acute process so \\npatient was discharged home.  \\n She now represents with generalized fatigue and diarrhea. In \\nthe setting of opiates for her L5 fracture, the patient has had \\nconstipation (5 days with no BM) for which she took a \"natural \\nlaxative\" the evening prior to presentation. The patient had 2 \\nbowel movements in the morning of presentation and one episode \\nof incontinence with diarrhea while sleeping. In this setting, \\nshe felt very weak and called EMS and was brought to ___ ED.  \\n In ___ ED:  \\n - Initial VS 98.7 72 130/46 16 99% RA  \\n - Labs notable for Chem-7 with BUN/Cr 36/1.1 otherwise wnl, CBC \\nwith H/H 7.8/25.4 (baseline Hct 31), iron studies with iron 49 \\nferritin 249, hemolysis labs with LDH 163 Tbili 0.2 hapto 170. \\nUA negative.  \\n - CXR without acute intrathoracic process. CT A/P without acute \\nprocess.  \\n - The patient was administered  \\n ___ 21:25 PO/NG OxyCODONE (Immediate Release) 2.5 mg  \\n ___ 21:25 PO/NG Gabapentin 100 mg  \\n ___ 21:25 PO/NG Thiamine 100 mg  \\n ___ 21:25 PO/NG FoLIC Acid 1 mg  \\n 1u pRBC transfusion started  \\n - VS prior to transfer 98.5 60 150/56 18 100% RA  \\n Upon arrival to the floor, VS 149/59 57 18 100%RA. The patient \\nis well-appearing and states that she already feels significant \\nbetter than when she first presented.ã€‚Please help me, using the medical record above, infer why each of this patient\\'s ICD-10 codes was assigned. Please respond in the specified format.', 'role': 'user'}, {'content': '<reasoning>Step-by-step reasoning:\\n1.  **D500 (Iron deficiency anemia secondary to blood loss (chronic))**: The medical record states \"PMH significant for chronic anemia\" and laboratory results show \"H/H 7.8/25.4 (baseline Hct 31), iron studies with iron 49 ferritin 249,\" which are indicative of iron deficiency. The need for \"1u pRBC transfusion\" further supports the severity of anemia.\\n2.  **E538 (Deficiency of other specified B group vitamins)**: The patient was administered \"FoLIC Acid 1 mg\" in the ED, suggesting a deficiency in this B group vitamin.\\n3.  **H548 (Blindness, low vision of both eyes, unspecified)**: Although not explicitly stated as a chief complaint or acute finding, \"recurrent falls\" in an elderly patient can often be attributed to or exacerbated by visual impairment. Given the code is provided, it\\'s inferred that this was part of the patient\\'s documented medical history or contributing factors to her falls.\\n4.  **I10 (Essential (primary) hypertension)**: The patient\\'s \"PMH significant for hypertension\" directly supports this code.\\n5.  **K521 (Toxic gastroenteritis and colitis)**: The patient reported taking a \"natural laxative\" which resulted in \"2 bowel movements in the morning of presentation and one episode of incontinence with diarrhea while sleeping,\" consistent with an inflammatory reaction of the gastrointestinal tract due to a toxic agent (the laxative).\\n6.  **M810 (Age-related osteoporosis without current pathological fracture)**: The patient\\'s \"PMH significant for osteoporosis\" directly supports this code, indicating the underlying bone condition. While she had an L5 fracture, M81.0 codes the chronic condition of osteoporosis itself.\\n7.  **R270 (Ataxia, unspecified)**: The patient\\'s \"PMH significant for ataxia\" directly supports this code. Ataxia would also contribute to the \"recurrent falls.\"\\n8.  **T474X5A (Adverse effect of other specified laxative, initial encounter)**: The patient\\'s symptoms of \"diarrhea\" and \"incontinence\" directly resulted from taking a \"natural laxative,\" classifying this as an adverse effect. \"Initial encounter\" indicates the patient is receiving active treatment for the acute effect.\\n9.  **Y92099 (Unspecified place of occurrence, not applicable)**: The patient \"presents from home\" after feeling weak and calling EMS. Her falls occurred \"from standing,\" which implies occurring within her home environment but without a more specific location.\\n10. **Z9181 (History of falling)**: The medical record explicitly mentions \"recurrent falls\" and details two separate fall incidents (\"s/p fall from standing at which time imaging revealed acute L5 fracture\" and \"s/p fall from standing while trying to reach for a glass of water\"), supporting a history of falling.\\n</reasoning><answer>D500,E538,H548,I10,K521,M810,R270,T474X5A,Y92099,Z9181</answer>', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# ==================== åƒæ•¸è¨­å®šå€ ====================\n",
    "# è¨­å®šæ¯å€‹è³‡æ–™é›†è¦é‡è¤‡çš„æ¬¡æ•¸\n",
    "DATASET1_REPEAT = 1  # gt_1_result.csv é‡è¤‡æ¬¡æ•¸\n",
    "DATASET2_REPEAT = 1  # 0.6_acc_result.csv é‡è¤‡æ¬¡æ•¸\n",
    "\n",
    "# CSV æª”æ¡ˆè·¯å¾‘\n",
    "DATASET1_FILE = \"gt_1_result.csv\"\n",
    "DATASET2_FILE = \"0.6_acc_result.csv\"\n",
    "# ===================================================\n",
    "\n",
    "# 1. è®€å–ç¬¬ä¸€å€‹ CSV æª”æ¡ˆ\n",
    "dataset1 = load_dataset(\"csv\", data_files=DATASET1_FILE, split=\"train\")\n",
    "print(f\"Dataset1 åŸå§‹ç­†æ•¸: {len(dataset1)}\")\n",
    "\n",
    "# 2. è®€å–ç¬¬äºŒå€‹ CSV æª”æ¡ˆ\n",
    "dataset2 = load_dataset(\"csv\", data_files=DATASET2_FILE, split=\"train\")\n",
    "print(f\"Dataset2 åŸå§‹ç­†æ•¸: {len(dataset2)}\")\n",
    "\n",
    "# 3. é‡å‘½åç¬¬äºŒå€‹è³‡æ–™é›†çš„ \"question\" æ¬„ä½ç‚º \"raw_question\"\n",
    "dataset2 = dataset2.rename_column(\"question\", \"raw_question\")\n",
    "\n",
    "# 4. æ ¹æ“šè¨­å®šçš„æ¯”ä¾‹é‡è¤‡è³‡æ–™é›†\n",
    "datasets_to_combine = []\n",
    "\n",
    "# é‡è¤‡ dataset1\n",
    "for _ in range(DATASET1_REPEAT):\n",
    "    datasets_to_combine.append(dataset1)\n",
    "\n",
    "# é‡è¤‡ dataset2\n",
    "for _ in range(DATASET2_REPEAT):\n",
    "    datasets_to_combine.append(dataset2)\n",
    "\n",
    "# 5. åˆä½µæ‰€æœ‰è³‡æ–™é›†\n",
    "combined_dataset = concatenate_datasets(datasets_to_combine)\n",
    "\n",
    "print(f\"\\nåˆä½µå¾Œç¸½ç­†æ•¸: {len(combined_dataset)}\")\n",
    "print(f\"  - Dataset1 è²¢ç»: {len(dataset1) * DATASET1_REPEAT} ç­†\")\n",
    "print(f\"  - Dataset2 è²¢ç»: {len(dataset2) * DATASET2_REPEAT} ç­†\")\n",
    "\n",
    "# 6. ä¿®æ”¹è½‰æ›å‡½æ•¸,å°æ‡‰æ‚¨çš„ CSV æ¬„ä½åç¨±\n",
    "def generate_conversation(examples):\n",
    "    problems = examples[\"raw_question\"]\n",
    "    solutions = examples[\"assistant_reply\"]\n",
    "    conversations = []\n",
    "    \n",
    "    for problem, solution in zip(problems, solutions):\n",
    "        conversations.append([\n",
    "            {\"role\": \"user\", \"content\": problem},\n",
    "            {\"role\": \"assistant\", \"content\": solution},\n",
    "        ])\n",
    "    \n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "# 7. åŸ·è¡Œè½‰æ›\n",
    "combined_dataset = combined_dataset.map(generate_conversation, batched=True)\n",
    "\n",
    "# 8. æª¢æŸ¥çµæœ\n",
    "print(f\"\\næœ€çµ‚è³‡æ–™é›†ç¸½ç­†æ•¸: {len(combined_dataset)}\")\n",
    "print(\"\\nç¬¬ä¸€ç­†å°è©±ç¯„ä¾‹:\")\n",
    "print(combined_dataset[0][\"conversations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e85ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1257/1257 [00:00<00:00, 4834.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "ä½ æ˜¯ä¸€åå°ˆé–€æ ¹æ“šæ‚£è€…ç”¨è—¥èˆ‡ç—…å²ç´€éŒ„é æ¸¬ ICD-10 ç·¨ç¢¼çš„é†«å­¸å°ˆå®¶ã€‚  \n",
      "ä½ å°‡æœƒå¾—çŸ¥ç—…äººçš„ICD-10ä»£ç¢¼è·Ÿç—…ä¾‹ä¸¦å›æ¨ç‚ºä»€éº¼ç—…äººçš„ICD-10æ˜¯å¦‚æ­¤ï¼š  \n",
      "\n",
      "<reasoning>  \n",
      "é€æ­¥æ¨ç†ï¼šé€æ¢èªªæ˜ç—…ä¾‹ä¸­æ¯å€‹è‡¨åºŠè³‡è¨Šï¼ˆç—‡ç‹€ã€è¨ºæ–·ã€æª¢æŸ¥çµæœã€æ—¢å¾€ç—…å²ã€ç”¨è—¥ç­‰ï¼‰å¯èƒ½å°æ‡‰çš„ ICD-10 ç·¨ç¢¼ï¼Œä¸¦åœ¨æœ€å¾Œç¸½çµç—…äººçš„ICD-10ç·¨ç¢¼é›†åˆã€‚  \n",
      "</reasoning>  \n",
      "<answer>  \n",
      "åƒ…è¼¸å‡ºæ­£ç¢ºçš„ ICD-10 ç·¨ç¢¼ï¼Œä½¿ç”¨è‹±æ–‡é€—è™Ÿåˆ†éš”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–æ–‡å­—æˆ–è§£é‡‹ã€‚  \n",
      "</answer>  \n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "There is a patient with the following ICD-10 codes:ï¼šD500,E538,H548,I10,K521,M810,R270,T474X5A,Y92099,Z9181. The medical record for the Patient is as follows:Sex:   F\n",
      " \n",
      "Service: MEDICINE\n",
      " \n",
      "Allergies: \n",
      "Aspirin\n",
      " \n",
      "Attending: ___.\n",
      " \n",
      "Chief Complaint:\n",
      "weakness, diarrhea\n",
      " \n",
      "Major Surgical or Invasive Procedure:\n",
      "None\n",
      "\n",
      " \n",
      "History of Present Illness:\n",
      "Ms. ___ is a ___ year-old woman with PMH significant for \n",
      "chronic anemia, osteoporosis, hypertension, ataxia, and recent \n",
      "L5 fracture in the setting of recurrent falls who presents from \n",
      "home with fatigue and generalized weakness and diarrhea.  \n",
      " The patient's recent history is notable for the follow:  \n",
      " - On ___, she presented with 4 days of LBP s/p fall from \n",
      "standing at which time imaging revealed acute L5 fracture. She \n",
      "was evaluated by Spine team who recommended early mobilization, \n",
      "pain control, but no brace required. She was evaluated by ___, \n",
      "and discharged to ___.  \n",
      " - She was discharged home with ___ on ___.  \n",
      " - On ___, she again presented to ___ s/p fall from \n",
      "standing while trying to reach for a glass of water. She did \n",
      "have a occipital scalp hematoma, but imaging including ___, \n",
      "C-spine CT, and L hip X-ray were negative for acute process so \n",
      "patient was discharged home.  \n",
      " She now represents with generalized fatigue and diarrhea. In \n",
      "the setting of opiates for her L5 fracture, the patient has had \n",
      "constipation (5 days with no BM) for which she took a \"natural \n",
      "laxative\" the evening prior to presentation. The patient had 2 \n",
      "bowel movements in the morning of presentation and one episode \n",
      "of incontinence with diarrhea while sleeping. In this setting, \n",
      "she felt very weak and called EMS and was brought to ___ ED.  \n",
      " In ___ ED:  \n",
      " - Initial VS 98.7 72 130/46 16 99% RA  \n",
      " - Labs notable for Chem-7 with BUN/Cr 36/1.1 otherwise wnl, CBC \n",
      "with H/H 7.8/25.4 (baseline Hct 31), iron studies with iron 49 \n",
      "ferritin 249, hemolysis labs with LDH 163 Tbili 0.2 hapto 170. \n",
      "UA negative.  \n",
      " - CXR without acute intrathoracic process. CT A/P without acute \n",
      "process.  \n",
      " - The patient was administered  \n",
      " ___ 21:25 PO/NG OxyCODONE (Immediate Release) 2.5 mg  \n",
      " ___ 21:25 PO/NG Gabapentin 100 mg  \n",
      " ___ 21:25 PO/NG Thiamine 100 mg  \n",
      " ___ 21:25 PO/NG FoLIC Acid 1 mg  \n",
      " 1u pRBC transfusion started  \n",
      " - VS prior to transfer 98.5 60 150/56 18 100% RA  \n",
      " Upon arrival to the floor, VS 149/59 57 18 100%RA. The patient \n",
      "is well-appearing and states that she already feels significant \n",
      "better than when she first presented.ã€‚Please help me, using the medical record above, infer why each of this patient's ICD-10 codes was assigned. Please respond in the specified format.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "<reasoning>Step-by-step reasoning:\n",
      "1.  **D500 (Iron deficiency anemia secondary to blood loss (chronic))**: The medical record states \"PMH significant for chronic anemia\" and laboratory results show \"H/H 7.8/25.4 (baseline Hct 31), iron studies with iron 49 ferritin 249,\" which are indicative of iron deficiency. The need for \"1u pRBC transfusion\" further supports the severity of anemia.\n",
      "2.  **E538 (Deficiency of other specified B group vitamins)**: The patient was administered \"FoLIC Acid 1 mg\" in the ED, suggesting a deficiency in this B group vitamin.\n",
      "3.  **H548 (Blindness, low vision of both eyes, unspecified)**: Although not explicitly stated as a chief complaint or acute finding, \"recurrent falls\" in an elderly patient can often be attributed to or exacerbated by visual impairment. Given the code is provided, it's inferred that this was part of the patient's documented medical history or contributing factors to her falls.\n",
      "4.  **I10 (Essential (primary) hypertension)**: The patient's \"PMH significant for hypertension\" directly supports this code.\n",
      "5.  **K521 (Toxic gastroenteritis and colitis)**: The patient reported taking a \"natural laxative\" which resulted in \"2 bowel movements in the morning of presentation and one episode of incontinence with diarrhea while sleeping,\" consistent with an inflammatory reaction of the gastrointestinal tract due to a toxic agent (the laxative).\n",
      "6.  **M810 (Age-related osteoporosis without current pathological fracture)**: The patient's \"PMH significant for osteoporosis\" directly supports this code, indicating the underlying bone condition. While she had an L5 fracture, M81.0 codes the chronic condition of osteoporosis itself.\n",
      "7.  **R270 (Ataxia, unspecified)**: The patient's \"PMH significant for ataxia\" directly supports this code. Ataxia would also contribute to the \"recurrent falls.\"\n",
      "8.  **T474X5A (Adverse effect of other specified laxative, initial encounter)**: The patient's symptoms of \"diarrhea\" and \"incontinence\" directly resulted from taking a \"natural laxative,\" classifying this as an adverse effect. \"Initial encounter\" indicates the patient is receiving active treatment for the acute effect.\n",
      "9.  **Y92099 (Unspecified place of occurrence, not applicable)**: The patient \"presents from home\" after feeling weak and calling EMS. Her falls occurred \"from standing,\" which implies occurring within her home environment but without a more specific location.\n",
      "10. **Z9181 (History of falling)**: The medical record explicitly mentions \"recurrent falls\" and details two separate fall incidents (\"s/p fall from standing at which time imaging revealed acute L5 fracture\" and \"s/p fall from standing while trying to reach for a glass of water\"), supporting a history of falling.\n",
      "</reasoning><answer>D500,E538,H548,I10,K521,M810,R270,T474X5A,Y92099,Z9181</answer><|im_end|>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# é€™è£¡ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„ Chat Template (ä¾‹å¦‚ Qwen, Llama ç­‰)\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# ç¢ºä¿ tokenizer çŸ¥é“è¦ç”¨å“ªç¨®æ ¼å¼ (é€™è¡Œé€šå¸¸åœ¨è¼‰å…¥æ¨¡å‹æ™‚æœƒåšï¼Œä½†ä¿éšªèµ·è¦‹å¯ä»¥åŠ )\n",
    "tokenizer = get_chat_template(tokenizer, chat_template = \"qwen-3\") \n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"ä½ æ˜¯ä¸€åå°ˆé–€æ ¹æ“šæ‚£è€…ç”¨è—¥èˆ‡ç—…å²ç´€éŒ„é æ¸¬ ICD-10 ç·¨ç¢¼çš„é†«å­¸å°ˆå®¶ã€‚  \n",
    "ä½ å°‡æœƒå¾—çŸ¥ç—…äººçš„ICD-10ä»£ç¢¼è·Ÿç—…ä¾‹ä¸¦å›æ¨ç‚ºä»€éº¼ç—…äººçš„ICD-10æ˜¯å¦‚æ­¤ï¼š  \n",
    "\n",
    "<reasoning>  \n",
    "é€æ­¥æ¨ç†ï¼šé€æ¢èªªæ˜ç—…ä¾‹ä¸­æ¯å€‹è‡¨åºŠè³‡è¨Šï¼ˆç—‡ç‹€ã€è¨ºæ–·ã€æª¢æŸ¥çµæœã€æ—¢å¾€ç—…å²ã€ç”¨è—¥ç­‰ï¼‰å¯èƒ½å°æ‡‰çš„ ICD-10 ç·¨ç¢¼ï¼Œä¸¦åœ¨æœ€å¾Œç¸½çµç—…äººçš„ICD-10ç·¨ç¢¼é›†åˆã€‚  \n",
    "</reasoning>  \n",
    "<answer>  \n",
    "åƒ…è¼¸å‡ºæ­£ç¢ºçš„ ICD-10 ç·¨ç¢¼ï¼Œä½¿ç”¨è‹±æ–‡é€—è™Ÿåˆ†éš”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–æ–‡å­—æˆ–è§£é‡‹ã€‚  \n",
    "</answer>  \n",
    "\"\"\"\n",
    "def formatting_prompts_func(examples):\n",
    "    conversations = examples[\"conversations\"]\n",
    "    texts = []\n",
    "    \n",
    "    for convo in conversations:\n",
    "        convo.insert(0, {\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "        text = tokenizer.apply_chat_template(\n",
    "                convo, \n",
    "                tokenize = False, \n",
    "                add_generation_prompt = False\n",
    "            )\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "# åŸ·è¡Œè½‰æ›ï¼šé€™æœƒç”¢ç”Ÿä¸€å€‹æ–°çš„ \"text\" æ¬„ä½\n",
    "dataset = combined_dataset.map(formatting_prompts_func, batched = True)\n",
    "\n",
    "# æª¢æŸ¥çµæœï¼šç¾åœ¨æ¨¡å‹çœŸæ­£çœ‹åˆ°çš„æ˜¯é€™å€‹æ¨£å­\n",
    "print(dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6645e90",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30a5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1257/1257 [00:03<00:00, 374.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 8,\n",
    "        gradient_accumulation_steps = 2, # Use GA to mimic batch size!\n",
    "        warmup_steps = 10,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 50,\n",
    "        learning_rate = 2e-4, # Reduce to 2ez-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_torch\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use TrackIO/WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8e60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,257 | Num Epochs = 1 | Total steps = 79\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 268,435,456 of 33,030,558,720 (0.81% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 1:44:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.528300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.176500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.931300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.922400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.892400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.886300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.879900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.870900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.829500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.821400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.859600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.706500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.840500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.944800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.733900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.855900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.810400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.733700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8e72f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: /mnt/data2/icd10/models/Qwen3-32B\n",
      "Found HuggingFace hub cache directory: /home/justin/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:   6%|â–Œ         | 1/17 [00:01<00:30,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00016-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  12%|â–ˆâ–        | 2/17 [00:03<00:24,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00017-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  18%|â–ˆâ–Š        | 3/17 [00:05<00:24,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00007-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  24%|â–ˆâ–ˆâ–       | 4/17 [00:07<00:23,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00015-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  29%|â–ˆâ–ˆâ–‰       | 5/17 [00:09<00:22,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00005-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:11<00:20,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00013-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:12<00:18,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00004-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:14<00:17,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00003-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 9/17 [00:16<00:15,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00011-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:18<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00010-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:20<00:11,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00006-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:22<00:09,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00002-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:24<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00014-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:26<00:05,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00008-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:28<00:03,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00001-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:30<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00009-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:32<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model-00012-of-00017.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [09:56<00:00, 35.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/mnt/data2/icd10/models/Qwen3-32B-sft`\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"{model_name}-sft\"\n",
    "\n",
    "# lora æ–¹å¼å„²å­˜\n",
    "model.save_pretrained_merged(save_path, tokenizer, save_method=\"merged_16bit\") \n",
    "\n",
    "# # ç›´æ¥å„²å­˜æ¨¡å‹èˆ‡ tokenizer\n",
    "# model.save_pretrained(save_path)\n",
    "# tokenizer.save_pretrained(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
