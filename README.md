# é‹ç”¨å¤§å‹èªè¨€æ¨¡å‹å¾®èª¿æŠ€è¡“æå‡ ICD-10 è¨ºæ–·ç·¨ç¢¼é æ¸¬æº–ç¢ºç‡
> [!NOTE]
> **[ç¹é«”ä¸­æ–‡](#ç¹é«”ä¸­æ–‡)** | **[English Version](#english-version)**

<a name="ç¹é«”ä¸­æ–‡"></a>
## ğŸ“– å°ˆæ¡ˆç°¡ä»‹ (Introduction)

æœ¬å°ˆæ¡ˆæ—¨åœ¨æ¢ç´¢å¦‚ä½•é€é **å¤§å‹èªè¨€æ¨¡å‹ (LLM)** çš„å¾®èª¿æŠ€è¡“ï¼Œå¾ç—…æ‚£çš„è‡¨åºŠè³‡è¨Šï¼ˆå¦‚ç—…æ­·ã€ç”¨è—¥ç´€éŒ„ï¼‰ä¸­ç²¾æº–æ¨ä¼° **ICD-10 è¨ºæ–·ä»£ç¢¼**ã€‚

å‚³çµ±æ–¹æ³•ï¼ˆå¦‚ BERTï¼‰åœ¨è™•ç†è¤‡é›œé†«ç™‚è„ˆçµ¡æ™‚å¾€å¾€é¢è‡¨ç“¶é ¸ï¼ˆF1 Score ç´„ 0.25ï¼‰ï¼Œä¸”ç¼ºä¹å°ä¸­æ–‡é†«ç™‚å°ˆæ¥­çŸ¥è­˜çš„ç†è§£ã€‚æœ¬ç ”ç©¶åˆ©ç”¨ **MIMIC-IV** è³‡æ–™åº«ï¼Œçµåˆ **å¼·åŒ–å­¸ç¿’ (GRPO)** èˆ‡ **ç›£ç£å¼å¾®èª¿ (SFT)**ï¼Œè‡´åŠ›æ–¼æå‡é†«ç™‚ç·¨ç¢¼å·¥ä½œçš„è‡ªå‹•åŒ–æ•ˆç‡èˆ‡æº–ç¢ºæ€§ã€‚

### æ ¸å¿ƒç›®æ¨™
* **ç²¾æº–é æ¸¬**ï¼šå¾éçµæ§‹åŒ–è‡¨åºŠæ–‡æœ¬ä¸­æå–ç‰¹å¾µï¼Œæº–ç¢ºé æ¸¬ ICD-10 ä»£ç¢¼ã€‚
* **æ•ˆç‡æå‡**ï¼šæ¸›å°‘äººå·¥ç·¨ç¢¼æ™‚é–“ï¼Œè¼”åŠ©é†«ç™‚è¡Œæ”¿æµç¨‹ã€‚
* **æŠ€è¡“æ¢ç´¢**ï¼šé©—è­‰ GRPO (Group Relative Policy Optimization) èˆ‡ç›£ç£å¼å¾®èª¿ (Supervised Fine-Tuning) åœ¨å¤šæ¨™ç±¤åˆ†é¡ä»»å‹™ä¸­çš„å„ªå‹¢ã€‚

---

##  å°ˆæ¡ˆçµæ§‹ (Project Structure)

æœ¬å€‰åº«çš„æª”æ¡ˆçµæ§‹çµ„ç¹”å¦‚ä¸‹ï¼š

```text
.
â”œâ”€â”€ Qwen3 baseline/           # Qwen3 åŸºç¤æ¨¡å‹çš„ Baseline æ¸¬è©¦ä»£ç¢¼èˆ‡çµæœ
â”œâ”€â”€ RL GRPO/                  # æœ¬å°ˆæ¡ˆæ ¸å¿ƒï¼šä½¿ç”¨ GRPO æ¼”ç®—æ³•é€²è¡Œå¼·åŒ–å­¸ç¿’å¾®èª¿çš„å¯¦ä½œä»£ç¢¼
â”œâ”€â”€ SFT/                      # æœ¬å°ˆæ¡ˆæ ¸å¿ƒï¼šSupervised Fine-Tuning (ç›£ç£å¼å¾®èª¿) ç›¸é—œå¯¦é©—ä»£ç¢¼
â”œâ”€â”€ medgemma baseline/        # ä½¿ç”¨ Google MedGemma æ¨¡å‹ä½œç‚ºå°ç…§çµ„çš„æ¸¬è©¦ä»£ç¢¼
â”œâ”€â”€ gemini API baseline/      # ä½¿ç”¨ Gemini API é€²è¡Œæ¸¬è©¦çš„åŸºæº–ä»£ç¢¼
â”œâ”€â”€ data preprocessing/       # MIMIC-IV åŸå§‹è³‡æ–™æ¸…æ´—èˆ‡å‰è™•ç†è…³æœ¬
â”œâ”€â”€ train data construction/  # ä½¿ç”¨Gemini 2.5 Flashçš„æ¨¡ç¯„å›ç­”å»ºæ§‹è¨“ç·´é›†çš„è…³æœ¬ 
â”œâ”€â”€ results/                   # å­˜æ”¾æ‰€æœ‰æ¨¡å‹å›ç­”è·Ÿå¯¦é©—çµæœ
â”œâ”€â”€ baseline_summary.ipynb    # å½™æ•´å„ Baseline æ¨¡å‹è¡¨ç¾çš„åˆ†æç­†è¨˜æœ¬
â”œâ”€â”€ note_icd_data.jsonl       # è™•ç†å¾Œçš„è‡¨åºŠç­†è¨˜èˆ‡ ICD å°æ‡‰æ•¸æ“š
â”œâ”€â”€ requirements.txt          # å°ˆæ¡ˆä¾è³´å¥—ä»¶æ¸…å–®
â”œâ”€â”€ requirements_sft.txt      # sft å°ˆæ¡ˆä¾è³´å¥—ä»¶æ¸…å–®
â””â”€â”€ ...
```
##  æ–¹æ³•è«– (Methodology)

### 1. ç›£ç£å¼å¾®èª¿èˆ‡çŸ¥è­˜è’¸é¤¾ (SFT & Knowledge Distillation)
åœ¨é€²è¡Œå¼·åŒ–å­¸ç¿’ä¹‹å‰ï¼Œæˆ‘å€‘å…ˆé€éçŸ¥è­˜è’¸é¤¾å»ºç«‹é«˜å“è³ªçš„åŸºç¤èƒ½åŠ›ï¼š

* **æ•¸æ“šåˆæˆ**ï¼šåˆ©ç”¨ **Gemini 2.5 Flash** ä½œç‚ºæ•™å¸«æ¨¡å‹ï¼Œé‡å°é†«ç™‚æ¡ˆä¾‹ç”Ÿæˆå…·å‚™è©³ç´°æ¨ç†é‚è¼¯ï¼ˆChain of Thoughtï¼‰çš„æ¨¡ç¯„å›ç­”ã€‚
* **æ¨¡å‹è’¸é¤¾**ï¼šå°‡åˆæˆçš„æ¨ç†æ•¸æ“šè¼¸å…¥ **Qwen 14B** é€²è¡Œç›£ç£å¼å¾®èª¿ (SFT)ï¼Œä½¿å…¶å¸æ”¶æ•™å¸«æ¨¡å‹çš„é†«ç™‚æ¨ç†è·¯å¾‘èˆ‡è¨ºæ–·é‚è¼¯ã€‚
* **æŠ€è¡“å¯¦ç¾**ï¼šæ¡ç”¨ Unsloth æ¡†æ¶ã€‚é€éå…¶å„ªåŒ–çš„æ ¸å¿ƒèˆ‡ Triton ç®—å­ï¼Œæˆ‘å€‘åœ¨å¾®èª¿éç¨‹ä¸­æˆåŠŸæ¸›å°‘äº†ç´„ 70% çš„é¡¯å­˜ä½”ç”¨ï¼Œä¸¦æå‡äº† 2 å€ä»¥ä¸Šçš„è¨“ç·´é€Ÿåº¦ã€‚

### 2. å¼·åŒ–å­¸ç¿’å¾®èª¿ (GRPO)
åœ¨ SFT åŸºç¤ä¸Šï¼Œæ¡ç”¨ DeepSeek æå‡ºçš„ **GRPO (Group Relative Policy Optimization)** æ¼”ç®—æ³•ï¼š

* **å„ªå‹¢**ï¼šä¸åŒæ–¼å‚³çµ± PPOï¼ŒGRPO ä¸éœ€è¦é¡å¤–çš„ Critic Networkï¼ˆè©•è«–å®¶æ¨¡å‹ï¼‰ï¼Œç¯€çœäº†å¤§é‡çš„é‹ç®—è³‡æºï¼Œæ¥µå…¶é©åˆåœ¨æœ‰é™é¡¯å­˜ä¸‹è™•ç†å…·æœ‰å¤šé …å€™é¸ä»£ç¢¼çš„è¤‡é›œä»»å‹™ã€‚
* **æ©Ÿåˆ¶**ï¼šé‡å°è¨ºæ–·ä»£ç¢¼çš„ æ ¼å¼æ­£ç¢ºæ€§ã€ä»£ç¢¼åŒ¹é…ç²¾æº–åº¦ ä»¥åŠ æ¨ç†é‚è¼¯çš„ä¸€è‡´æ€§ è¨­å®šçå‹µå‡½æ•¸ï¼Œå¼·åˆ¶æ¨¡å‹åœ¨è¼¸å‡ºæ™‚ä¸åƒ…æä¾›æ­£ç¢ºç·¨ç¢¼ï¼Œé‚„å¿…é ˆæä¾›åˆç†çš„è‡¨åºŠè­‰æ“šæ”¯æŒã€‚

### 3. æç¤ºå·¥ç¨‹ (Prompt Engineering)
è¨­è¨ˆå°ˆç”¨çš„ System Prompt å°‡æ¨¡å‹å®šä½ç‚ºã€Œå°ˆæ¥­é†«ç™‚ç·¨ç¢¼ç¨½æ ¸å“¡ã€ï¼š

* **CoT å¼•å°**ï¼šå¼·åˆ¶æ¨¡å‹å¿…é ˆå…ˆåˆ†æç—…å²èˆ‡ç”¨è—¥ï¼Œæœ€å¾Œå†åˆ—å‡º ICD-10 Codeã€‚

* **è¼¸å‡ºç´„æŸ**ï¼šå®šç¾©æ¨™æº–åŒ–çš„ JSON æˆ–æ¨™ç±¤æ ¼å¼ï¼Œç¢ºä¿æ¨¡å‹é æ¸¬çµæœå¯è¢«ä¸‹æ¸¸è¡Œæ”¿ç³»çµ±ç›´æ¥è§£æã€‚

### 4. å¯¦é©—æ•¸æ“šé›†
* **ä¾†æº**ï¼šMIMIC-IV (MIT-LCP)
* **å…§å®¹**ï¼šæ¶µè“‹é‡ç—‡ç›£è­·ç—…æ‚£çš„ç—…å²ã€ä¸»è¨´ã€è©³ç´°ç”¨è—¥ç´€éŒ„åŠå°ˆæ¥­äººå“¡æ¨™è¨»çš„æ¨™æº– ICD-10 ä»£ç¢¼ã€‚

---

##  å¯¦é©—çµæœ (Results)

æˆ‘å€‘æ¯”è¼ƒäº†ä¸åŒæ¨¡å‹è¦æ¨¡èˆ‡æ–¹æ³•åœ¨ ICD-10 é æ¸¬ä»»å‹™ä¸Šçš„è¡¨ç¾ (F1 Score)ï¼š

| Model / Method | è¡¨ç¾ (Average F1 Score) | å‚™è¨» |
| :--- | :--- | :--- |
| **MedGemma 4B** | ~0.1064 | é‡å°é†«ç™‚å„ªåŒ–çš„åŸºç¤æ¨¡å‹ï¼Œä½†å¯¦éš›å¯¦é©—ä¹‹è¡¨ç¾æœ‰é™ |
| **Qwen3 4B** | ~0.1813 | é€šç”¨æ¨¡å‹ Baseline |
| **Qwen3 14B** | ~0.2748 | è¼ƒå¤§åƒæ•¸æ¨¡å‹è¡¨ç¾æ›´ä½³ |
| **Qwen3 14B + SFT** | ~0.2970 | SFT å¾Œæ¨¡å‹æ¨ç†æ ¼å¼ç›¸ç•¶ç©©å®š |
| **Qwen3 14B + SFT + RL** | ~0.3127 | RL å¾Œæ¨¡å‹é†«å­¸çŸ¥è­˜æ¨ç†è¡¨ç¾æ›´åŠ æå‡ |
| *Gemini 2.5 Flash* | *~0.3357* | *Teacher æ¨¡å‹ (çŸ¥è­˜ä¾†æº)* |

ä¸‹åœ–æ›´è©³ç´°åœ°å±•ç¤ºäº† Qwen-14B åœ¨ä¸åŒè¨“ç·´éšæ®µï¼ˆBase, SFT, RLï¼‰èˆ‡ Gemini Pro å°ç…§çµ„ï¼Œåœ¨ä¸åŒé æ¸¬æ•¸é‡ (Top-K) ä¸‹çš„ F1 Score è¡¨ç¾è¶¨å‹¢ï¼š

![ä¸åŒæ¨¡å‹èˆ‡å¾®èª¿éšæ®µçš„ F1 Score æ¯”è¼ƒåœ–](./graph/14B%20GRPO%20vs%20SFT%20vs%20base%20vs%20gemini_v0.png)
*åœ– 1ï¼šä¸åŒæ¨¡å‹åœ¨ Top-K é æ¸¬ä¸­çš„ F1 Score è¡¨ç¾æ¯”è¼ƒã€‚å¯è¦‹ç¶“é RL (GRPO) å¾®èª¿å¾Œçš„æ¨¡å‹ï¼Œåœ¨å„é …æŒ‡æ¨™ä¸Šå‡å„ªæ–¼ SFT èˆ‡ Base ç‰ˆæœ¬ï¼Œä¸¦é€æ­¥é€¼è¿‘ Gemini Pro çš„è¡¨ç¾ã€‚*

 ** çµæœåˆ†æ**ï¼š
* **å„ªåŒ–æˆæ•ˆé¡¯è‘—**ï¼š
    Qwen3 14B åœ¨åŠ å…¥ **RL (GRPO)** å¼·åŒ–å­¸ç¿’å¾Œï¼ŒF1 åˆ†æ•¸è¼ƒåŸå§‹ Base ç‰ˆæœ¬æå‡äº†ç´„ **13.8%**ã€‚é€™è­‰æ˜äº†å¼·åŒ–å­¸ç¿’èƒ½æœ‰æ•ˆæ ¡æº–æ¨¡å‹åœ¨è™•ç†è¤‡é›œé†«ç™‚ä»»å‹™æ™‚çš„æ±ºç­–å“è³ªã€‚
* **çŸ¥è­˜è’¸é¤¾èˆ‡æ ¼å¼ç©©å®š**ï¼š
    **SFT éšæ®µ**æˆåŠŸå°‡ Gemini çš„æ¨ç†èƒ½åŠ›è’¸é¤¾è‡³ Qwen æ¨¡å‹ä¸­ï¼Œæœ‰æ•ˆè§£æ±ºäº†é†«ç™‚ç·¨ç¢¼ä¸­å¸¸è¦‹çš„è¼¸å‡ºæ ¼å¼ä¸ç©©å®šå•é¡Œï¼Œç‚ºå¾ŒçºŒçš„ RL å„ªåŒ–å¥ å®šäº†å …å¯¦åŸºç¤ã€‚
* **RL èª˜å°ä¹‹æ¨ç†èƒ½åŠ›æå‡**ï¼š
    é€é RL éšæ®µçš„çå‹µæ©Ÿåˆ¶ï¼ˆReward Functionï¼‰ï¼Œæ¨¡å‹ä¸åƒ…å­¸æœƒéµå®ˆæ­£ç¢ºæ ¼å¼ï¼Œæ›´èƒ½æ·±å±¤ç†è§£**é†«å­¸ç—…æ­·æ–‡æœ¬**èˆ‡ **ICD-10 æ¨™æº–ä»£ç¢¼**é–“çš„é‚è¼¯é—œè¯ï¼Œä½¿æ¨ç†è¡¨ç¾é€²ä¸€æ­¥é€¼è¿‘ Gemini 2.5 Flashã€‚
* **æ€§èƒ½å·®è·ç¸®å°**ï¼š
    ç¶“éå„ªåŒ–çš„ Qwen3 14B è¡¨ç¾å·²æœ‰æ•ˆæ¥è¿‘å•†æ¥­å¼·å¤§æ¨¡å‹ã€‚é€™è­‰æ˜äº†ã€Œ**SFT + GRPO**ã€çš„è¨“ç·´æµç¨‹åœ¨é†«ç™‚ç·¨ç¢¼ç­‰ç‰¹å®šå‚ç›´é ˜åŸŸä¸­ï¼Œå…·æœ‰æ¥µé«˜çš„è½åœ°æ‡‰ç”¨æ½›åŠ›ã€‚
---


##  å®‰è£èˆ‡ä½¿ç”¨ (Getting Started)

### ç’°å¢ƒéœ€æ±‚
```bash
pip install -r requirements.txt
pip install -r requirements_sft.txt
```
### ğŸ› ï¸ æ•¸æ“šæº–å‚™

è«‹ç¢ºä¿æ‚¨æ“æœ‰ **MIMIC-IV** çš„å­˜å–æ¬Šé™ï¼Œä¸¦å°‡åŸå§‹æª”æ¡ˆæ”¾å…¥ `data preprocessing` æŒ‡å®šçš„è·¯å¾‘ä¸­åŸ·è¡Œæ¸…æ´—è…³æœ¬ã€‚

---

##  å¼•ç”¨èˆ‡è‡´è¬ (Citation)

æœ¬å°ˆæ¡ˆä½¿ç”¨äº† **MIMIC-IV** è³‡æ–™åº«ï¼Œä¸¦çµåˆäº†é«˜æ•ˆçš„å¾®èª¿èˆ‡å¼·åŒ–å­¸ç¿’æŠ€è¡“ã€‚

* **Data Citation**: Johnson, A., Bulgarelli, L., Pollard, T., ... Mark, R. (2023). MIMIC-IV. PhysioNet.
* **Technical References**:
    * **Unsloth**: Used for efficient **SFT** (Supervised Fine-Tuning) and memory optimization during training.
    * **DeepSeek GRPO Algorithm**: Used for Group Relative Policy Optimization to enhance reasoning capabilities.
* **Last updated**: 2025/12


<a name="english-version"></a>
# Enhancing ICD-10 Diagnostic Coding Accuracy via LLM Fine-Tuning

## ğŸ“– Project Overview (Introduction)

This project explores how **large language model (LLM)** fine-tuning techniques can be used to accurately predict **ICD-10 diagnostic codes** from patientsâ€™ clinical information (such as clinical notes and medication records).

Traditional approaches (e.g., BERT-based models) often struggle with complex medical contexts, achieving limited performance (F1 score around 0.25), and lack sufficient understanding of Chinese medical terminology. Leveraging the **MIMIC-IV** database, this study integrates **Reinforcement Learning (GRPO)** and **Supervised Fine-Tuning (SFT)** to improve the automation efficiency and accuracy of medical coding.

### Core Objectives

* **Accurate Prediction**: Extract meaningful features from unstructured clinical text to precisely predict ICD-10 codes.
* **Efficiency Improvement**: Reduce manual coding time and support medical administrative workflows.
* **Technical Exploration**: Validate the effectiveness of GRPO (Group Relative Policy Optimization) and Supervised Fine-Tuning in multi-label classification tasks.

---

## ğŸ“‚ Project Structure

The repository is organized as follows:

```text
.
â”œâ”€â”€ Qwen3 baseline/            # Baseline experiments and results using the Qwen3 base model
â”œâ”€â”€ RL GRPO/                   # Core component: reinforcement learning fine-tuning with the GRPO algorithm
â”œâ”€â”€ SFT/                       # Core component: Supervised Fine-Tuning (SFT) experiments
â”œâ”€â”€ medgemma baseline/         # Baseline experiments using Google MedGemma as a comparison model
â”œâ”€â”€ gemini API baseline/       # Baseline experiments using the Gemini API
â”œâ”€â”€ data preprocessing/        # Scripts for cleaning and preprocessing raw MIMIC-IV data
â”œâ”€â”€ train data construction/   # Scripts for constructing training data using exemplar answers from Gemini 2.5 Flash
â”œâ”€â”€ result/                    # Model outputs and experimental results
â”œâ”€â”€ baseline_summary.ipynb     # Notebook summarizing and analyzing baseline model performance
â”œâ”€â”€ note_icd_data.jsonl        # Processed clinical notes paired with ICD-10 codes
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ requirements_sft.txt       # Dependencies specific to SFT experiments
â””â”€â”€ ...
```

---

## ğŸ§  Methodology

### 1. Supervised Fine-Tuning & Knowledge Distillation (SFT)

Before reinforcement learning, we first establish strong baseline capabilities through knowledge distillation:

* **Data Synthesis**: Use **Gemini 2.5 Flash** as a teacher model to generate exemplar answers with detailed reasoning chains (Chain of Thought) for medical cases.
* **Model Distillation**: Feed the synthesized reasoning data into **Qwen 14B** for Supervised Fine-Tuning (SFT), enabling the model to absorb the teacherâ€™s medical reasoning pathways and diagnostic logic.
* **Technical Implementation**: The **Unsloth** framework is adopted. With its optimized core and Triton kernels, GPU memory usage is reduced by approximately 70%, while training speed is increased by more than 2Ã—.

### 2. Reinforcement Learning Fine-Tuning (GRPO)

Building on the SFT model, we further apply **GRPO (Group Relative Policy Optimization)** proposed by DeepSeek:

* **Advantages**: Unlike traditional PPO, GRPO does not require an additional critic network, significantly reducing computational overhead. This makes it particularly suitable for complex tasks with multiple candidate codes under limited GPU memory.
* **Mechanism**: Reward functions are designed to enforce **output format correctness**, **code matching accuracy**, and **consistency of clinical reasoning**, ensuring that the model not only outputs correct ICD-10 codes but also provides clinically plausible justifications.

### 3. Prompt Engineering

A dedicated system prompt is designed to position the model as a *professional medical coding auditor*:

* **Chain-of-Thought Guidance**: The model is required to first analyze patient history and medications, and only then output the ICD-10 codes.
* **Output Constraints**: Standardized JSON or tagged formats are enforced so that predictions can be directly parsed by downstream administrative systems.

### 4. Experimental Dataset

* **Source**: MIMIC-IV (MIT-LCP)
* **Content**: Includes ICU patient histories, chief complaints, detailed medication records, and professionally annotated ICD-10 codes.

---

## ğŸ“Š Experimental Results

We compare different model sizes and methods on the ICD-10 prediction task using the F1 score:

| Model / Method           | Performance (Average F1 Score) | Notes                                                             |
| :----------------------- | :----------------------------- | :---------------------------------------------------------------- |
| **MedGemma 4B**          | ~0.1064                        | Medical-optimized base model, but limited performance in practice |
| **Qwen3 4B**             | ~0.1813                        | General-purpose baseline model                                    |
| **Qwen3 14B**            | ~0.2514                        | Larger model achieves better performance                          |
| **Qwen3 14B + SFT**      | ~0.2775                        | More stable reasoning format after SFT                            |
| **Qwen3 14B + SFT + RL** | ~0.2958                        | Further improvement in medical reasoning after RL                 |
| *Gemini 2.5 Flash*       | *~0.3255*                      | *Teacher model (knowledge source)*                                |

![Comparison of F1 Scores across different models and fine-tuning stages](./graph/14B%20SFT%20vs%2014B%20base%20vs%20gemini_v0.png)
*Figure 1: Comparison of F1 Score performance across different models in Top-K predictions. It is evident that the model fine-tuned with RL (GRPO) outperforms both the SFT and Base versions across all metrics, progressively approaching the performance of Gemini Pro.*

### ğŸ’¡ Result Analysis

* **Significant Optimization Impact**
    After incorporating **RL (GRPO)**, the F1 score of Qwen3 14B improved by approximately **13.8%** compared to the original Base version. This demonstrates that reinforcement learning can effectively calibrate the model's decision-making quality when handling complex and high-stakes medical tasks.

* **Knowledge Distillation & Structural Stability**
    The **SFT phase** successfully distilled reasoning capabilities from Gemini into the Qwen model. This stage was critical in resolving output format instabilityâ€”a common challenge in automated medical codingâ€”thereby establishing a stable foundation for subsequent RL optimization.

* **RL-Driven Reasoning Enhancement**
    Through the implementation of specialized **Reward Functions** during the RL phase, the model did not merely learn to adhere to formatting constraints; it developed a deeper cognitive grasp of the logical correlations between **unstructured medical record texts** and **standardized ICD-10 codes**. This advancement brought its reasoning performance significantly closer to that of Gemini 2.5 Flash.

* **Bridging the Performance Gap**
    The results indicate that the optimized Qwen3 14B has effectively narrowed the performance gap with state-of-the-art commercial models. This validates that the **"SFT + GRPO"** training pipeline holds immense potential for practical, privacy-compliant deployment in specialized vertical domains such as healthcare and medical insurance.
---

## ğŸš€ Getting Started

### Environment Setup

```bash
pip install -r requirements.txt
pip install -r requirements_sft.txt
```

### ğŸ› ï¸ Data Preparation

Please ensure that you have authorized access to **MIMIC-IV**, and place the raw files into the designated paths under `data preprocessing` before running the cleaning scripts.

---

## ğŸ“š Citation & Acknowledgements

This project utilizes the **MIMIC-IV** database and integrates efficient fine-tuning and reinforcement learning techniques.

* **Data Citation**: Johnson, A., Bulgarelli, L., Pollard, T., ... Mark, R. (2023). *MIMIC-IV*. PhysioNet.

* **Technical References**:

  * **Unsloth**: Used for efficient **SFT (Supervised Fine-Tuning)** and GPU memory optimization during training.
  * **DeepSeek GRPO Algorithm**: Used for Group Relative Policy Optimization to enhance reasoning capabilities.

* **Last updated**: 2025/12
